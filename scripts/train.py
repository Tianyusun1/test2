# File: tianyusun1/test2/test2-5.2/scripts/train.py (V5.18: Final RL Loop & Saving Logic)

# --- å¼ºåˆ¶æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python æ¨¡å—æœç´¢è·¯å¾„ ---
import sys
import os
import argparse 

# è·å–å½“å‰è„šæœ¬ (train.py) çš„ç»å¯¹è·¯å¾„
current_script_path = os.path.abspath(__file__)
# è·å–é¡¹ç›®æ ¹ç›®å½• (train.py çš„çˆ¶ç›®å½•)
project_root = os.path.dirname(os.path.dirname(current_script_path))
# å°†é¡¹ç›®æ ¹ç›®å½•æ’å…¥åˆ° sys.path çš„å¼€å¤´
sys.path.insert(0, project_root)

# --- ç°åœ¨å¯ä»¥å®‰å…¨åœ°å¯¼å…¥é¡¹ç›®å†…éƒ¨æ¨¡å— ---
import torch
from torch.utils.data import DataLoader
import yaml
from transformers import BertTokenizer
from data.dataset import PoegraphLayoutDataset, layout_collate_fn 
from models.poem2layout import Poem2LayoutGenerator
import trainers 
from trainers.rl_trainer import RLTrainer 
from collections import Counter
import numpy as np 

# --- è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—ç±»åˆ«æƒé‡ (è§£å†³ç±»åˆ«åå·®é—®é¢˜) ---
def compute_class_weights(dataset, num_classes: int, max_weight_ratio: float = 3.0):
    """
    è®¡ç®—æ•°æ®é›†å†…æ‰€æœ‰å¸ƒå±€å…ƒç´ çš„ç±»åˆ«é¢‘ç‡ï¼Œå¹¶è¿”å›åå‘é¢‘ç‡æƒé‡ã€‚
    è¿”å› (num_classes + 1) ä¸ªæƒé‡ï¼Œå…¶ä¸­ç´¢å¼• 0 å¯¹åº” EOSã€‚
    """
    element_class_counts = Counter()
    
    # éå†æ•´ä¸ªæ•°æ®é›†è®¡ç®—æ‰€æœ‰å…ƒç´ å®ä¾‹çš„ç±»åˆ«è®¡æ•°
    for sample in dataset.data:
        # boxes æ˜¯ List[(cls_id, cx, cy, w, h)]ï¼Œcls_id æ˜¯ 2.0 - 10.0
        for cls_id_float, _, _, _, _ in sample['boxes']:
            # æ˜ å°„åˆ°å†…éƒ¨ ID 0-8 (å¯¹åº”å…ƒç´  2-10)
            internal_element_id = int(cls_id_float) - 2
            if 0 <= internal_element_id < num_classes:
                element_class_counts[internal_element_id] += 1
                
    total_count = sum(element_class_counts.values())
    
    # æœ€ç»ˆæƒé‡æ•°ç»„å¤§å°å¿…é¡»æ˜¯ 9 (å…ƒç´ ) + 1 (EOS) = 10
    final_num_classes = num_classes + 1 
    
    if total_count == 0:
        print("[Warning] No valid elements found in dataset for weight calculation. Using uniform weights.")
        return torch.ones(final_num_classes)

    # åˆå§‹åŒ–æƒé‡: size 10 (ç´¢å¼• 0 for EOS, ç´¢å¼• 1-9 for elements)
    weights = torch.zeros(final_num_classes) 
    
    # è®¡ç®— 9 ä¸ªå…ƒç´  (å†…éƒ¨ ID 0-8) çš„æƒé‡ï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ç´¢å¼• 1-9
    for i in range(num_classes): # i goes from 0 to 8 (internal element ID)
        frequency = element_class_counts.get(i, 0) / total_count
        
        # å°†å…ƒç´ çš„å†…éƒ¨ ID i (0-8) æ˜ å°„åˆ°æ–°çš„ç´¢å¼• i+1 (1-9)
        new_index = i + 1 
        
        if frequency > 0:
            # é‡‡ç”¨ log(1.0 + x) æˆ– log(1.02 + x) æ¥å¹³æ»‘å’Œåè½¬é¢‘ç‡
            weights[new_index] = 1.0 / np.log(1.02 + frequency) 
        else:
            # å¯¹äºç¨€æœ‰/ä¸å­˜åœ¨çš„ç±»åˆ«ï¼Œèµ‹äºˆæœ€é«˜çš„æƒé‡
            weights[new_index] = 1.0 / np.log(1.02 + 1e-6) # èµ‹äºˆæœ€å¤§æƒé‡
            
    # ä¸º EOS ç±» (ç´¢å¼• 0) åˆ†é…æƒé‡
    # æˆ‘ä»¬ä½¿ç”¨è®¡ç®—å‡ºçš„å…ƒç´ æƒé‡çš„å¹³å‡å€¼ä½œä¸ºåŸºçº¿
    avg_element_weight = weights[1:].sum() / num_classes if num_classes > 0 else 1.0
    weights[0] = avg_element_weight # å°†å¹³å‡æƒé‡åˆ†é…ç»™ EOS (ç´¢å¼• 0)
            
    # æƒé‡é’³ä½å’Œæ ‡å‡†åŒ–
    # å¯¹æ‰€æœ‰ 10 ä¸ªç±»åˆ«è®¡ç®—å¹³å‡æƒé‡
    avg_weight = weights.mean()
    max_allowed_weight = avg_weight * max_weight_ratio
    weights = torch.clamp(weights, max=max_allowed_weight)
    
    # é‡æ–°å½’ä¸€åŒ–ï¼Œç¡®ä¿æ€»å’Œæ˜¯ final_num_classes (10)
    weights = weights / weights.sum() * final_num_classes
    
    return weights.float()
# ------------------------------------------


def main():
    # [NEW] æ·»åŠ å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="Train or RL-Finetune Poem2Layout")
    parser.add_argument('--rl_tuning', action='store_true', help="Enable Reinforcement Learning fine-tuning mode")
    parser.add_argument('--checkpoint', type=str, default=None, help="Path to pretrained model checkpoint (required for RL tuning)")
    args = parser.parse_args()

    # 1. Load config
    config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "configs/default.yaml")
    with open(config_path, "r") as f:
        config = yaml.safe_load(f)

    # 2. Init tokenizer and load FULL dataset for weight calculation
    model_config = config['model']
    train_config = config['training'] # è·å– training é…ç½®å—
    
    # é‡æ–°åˆå§‹åŒ–æ•°æ®é›†ä»¥ç¡®ä¿æ•°æ®å®Œæ•´æ€§
    dataset = PoegraphLayoutDataset(
        xlsx_path=model_config['xlsx_path'],
        labels_dir=model_config['labels_dir'],
        bert_model_path=model_config['bert_path'],
        max_layout_length=model_config['max_layout_length'],
        max_text_length=model_config['max_text_length']
    )
    
    # --- è®¡ç®—ç±»åˆ«æƒé‡ ---
    num_element_classes = model_config['num_classes'] # 9
    class_weights_tensor = compute_class_weights(dataset, num_element_classes)
    
    print(f"Calculated Class Weights (Internal 0:EOS, 1-9:Elements 2-10): {class_weights_tensor.tolist()}")
    # ---------------------------

    # 3. Init model (ä¼ å…¥æ‰€æœ‰æŸå¤±æƒé‡ï¼ŒåŒ…æ‹¬æ–°å¢çš„ Clustering Loss)
    print(f"Initializing model with latent_dim={model_config.get('latent_dim', 32)}...")
    model = Poem2LayoutGenerator(
        bert_path=model_config['bert_path'],
        num_classes=num_element_classes, # å®é™…å…ƒç´ ç±»åˆ«æ•° (9)
        # --- BBox Discrete Parameters (Legacy) ---
        num_bbox_bins=model_config.get('num_bbox_bins', 1000),
        bbox_embed_dim=model_config.get('bbox_embed_dim', 24),
        # --------------------------------------
        hidden_size=model_config['hidden_size'],
        bb_size=model_config['bb_size'],
        decoder_layers=model_config['decoder_layers'],
        decoder_heads=model_config['decoder_heads'],
        dropout=model_config['dropout'],
        
        # === CVAE å‚æ•° ===
        latent_dim=model_config.get('latent_dim', 32),
        
        # --- ä¼ å…¥æ‰€æœ‰æŸå¤±æƒé‡ (Updated for V5.4) ---
        coord_loss_weight=model_config.get('coord_loss_weight', 0.0),
        iou_loss_weight=model_config.get('iou_loss_weight', 1.0), 
        reg_loss_weight=model_config.get('reg_loss_weight', 1.0),    
        cls_loss_weight=model_config.get('cls_loss_weight', 0.0),    
        count_loss_weight=model_config.get('count_loss_weight', 0.0),
        area_loss_weight=model_config.get('area_loss_weight', 1.0),
        
        # æ ¸å¿ƒé€»è¾‘æƒé‡
        relation_loss_weight=model_config.get('relation_loss_weight', 5.0),
        overlap_loss_weight=model_config.get('overlap_loss_weight', 3.0),
        size_loss_weight=model_config.get('size_loss_weight', 2.0),
        
        # å®¡ç¾æƒé‡
        alignment_loss_weight=model_config.get('alignment_loss_weight', 0.0),
        balance_loss_weight=model_config.get('balance_loss_weight', 0.0),
        
        # [NEW V5.4] èšç±»æŸå¤±æƒé‡
        clustering_loss_weight=model_config.get('clustering_loss_weight', 1.0),
        
        class_weights=class_weights_tensor 
        # -----------------------------------------
    )

    # 4. Split dataset and init data loaders
    total_size = len(dataset)
    train_size = int(0.8 * total_size) # 80%
    val_size = int(0.1 * total_size)   # 10%
    test_size = total_size - train_size - val_size # å‰©ä½™ä¸º 10%

    # æ‰§è¡Œ 80/10/10 éšæœºåˆ’åˆ†
    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size, test_size]
    )
    print(f"Dataset split: Train={train_size}, Validation={val_size}, Test={test_size}")

    # [NOTE] Batch Size è¯»å–è‡ªé…ç½®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ yaml ä¸­ batch_size å·²è®¾ç½®ä¸º 128
    batch_size = train_config['batch_size']
    print(f"Using Batch Size: {batch_size}")

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        collate_fn=layout_collate_fn,
        num_workers=4, # å¤§æ‰¹é‡æ•°æ®å»ºè®®å¼€å¯å¤šçº¿ç¨‹åŠ è½½
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        collate_fn=layout_collate_fn,
        num_workers=4,
        pin_memory=True
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        collate_fn=layout_collate_fn,
        num_workers=4,
        pin_memory=True
    )
    
    # --- è·å– tokenizer å’Œä¸€ä¸ªå›ºå®šæ ·ä¾‹ ---
    tokenizer = dataset.tokenizer 
    # ä»éªŒè¯é›†ä¸­é€‰æ‹©ç¬¬ä¸€ä¸ªæ ·ä¾‹
    example_idx_in_full_dataset = val_dataset.indices[0]
    example_poem = dataset.data[example_idx_in_full_dataset]
    
    # **æ‰“å°å›ºå®šæ¨ç†æ ·ä¾‹çš„ KG å‘é‡å’Œç©ºé—´çŸ©é˜µ**
    # è¿™å¯¹äºè°ƒè¯• RL æ˜¯å¦èƒ½è·å–åˆ° Relation Reward éå¸¸é‡è¦
    print("\n---------------------------------------------------")
    print(f"Inference Example Poem: '{example_poem['poem']}'")
    print(f"Inference Example GT Boxes: {example_poem['boxes']}")
    print("-------------------- KG DEBUG ---------------------")
    
    # 1. è§†è§‰å‘é‡
    kg_vector_example = dataset.pkg.extract_visual_feature_vector(example_poem['poem'])
    print(f"KG Vector (0:mountain(2), 1:water(3), ..., 8:animal(10)): {kg_vector_example.tolist()}")
    
    # 2. [NEW] ç©ºé—´çŸ©é˜µ
    kg_spatial_matrix_example = dataset.pkg.extract_spatial_matrix(example_poem['poem'])
    print("Spatial Matrix (9x9):")
    print(kg_spatial_matrix_example)
    print("---------------------------------------------------\n")

    # 5. Logic Branch: RL Tuning OR Supervised Training
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    if args.rl_tuning:
        print("\n=======================================================")
        print(">>> ENTERING RL FINE-TUNING MODE (SCST) <<<")
        print("=======================================================\n")
        
        # 1. å¿…é¡»åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if args.checkpoint is None:
            raise ValueError("RL tuning requires a pretrained checkpoint! Use --checkpoint")
        
        print(f"Loading pretrained model from {args.checkpoint}...")
        # map_location ç¡®ä¿åœ¨ CPU/GPU é—´è¿ç§»å…¼å®¹
        checkpoint = torch.load(args.checkpoint, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        
        # 2. è¯»å– RL é…ç½®å‚æ•° [FIXED: å¼ºåˆ¶ç±»å‹è½¬æ¢]
        # åŠ¡å¿…è½¬ä¸º float å’Œ intï¼Œé˜²æ­¢ YAML è§£æä¸º string å¯¼è‡´ optimizer æŠ¥é”™
        rl_lr = float(train_config.get('rl_learning_rate', 5e-6))
        rl_epochs = int(train_config.get('rl_epochs', 50))
        
        print(f"RL Config -> Learning Rate: {rl_lr:.2e} (float) | Epochs: {rl_epochs} (int)")

        # 3. åˆå§‹åŒ– RLTrainer
        trainer = RLTrainer(model, train_loader, val_loader, config, tokenizer, example_poem, test_loader)
        
        # 4. å¼ºåˆ¶è¦†ç›–ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡
        for param_group in trainer.optimizer.param_groups:
            param_group['lr'] = rl_lr
        
        # [NEW] åˆå§‹åŒ–æœ€ä½³å¥–åŠ±è®°å½•
        best_reward = -float('inf')

        # 5. å¼€å§‹ RL è®­ç»ƒå¾ªç¯
        for epoch in range(rl_epochs):
            # [MODIFIED] æ¥æ”¶ train_rl_epoch è¿”å›çš„ avg_reward
            avg_reward = trainer.train_rl_epoch(epoch)
            
            # [NEW] å¯è§†åŒ–ï¼šæ¯è½® RL ç»“æŸç”Ÿæˆä¸€å¼ æ ·ä¾‹å›¾ï¼Œç›´è§‚çœ‹åˆ°æ¨¡å‹å˜åŒ–
            # print(f"--- Visualizing RL Progress (Epoch {epoch+1}) ---")
            # è°ƒç”¨ Trainer å†…éƒ¨çš„æ¨ç†å‡½æ•°ï¼Œå®ƒä¼šç”Ÿæˆ png åˆ° outputs/
            trainer._run_inference_example(epoch)
            
            # === [NEW] ä¿å­˜é€»è¾‘ A: ä¿å­˜æœ€æ£’çš„æ¨¡å‹ (Best Reward) ===
            # è¿™æ˜¯ infer.py ä¼˜å…ˆåŠ è½½çš„æ¨¡å‹
            if avg_reward > best_reward:
                best_reward = avg_reward
                best_save_path = os.path.join(train_config['output_dir'], "rl_best_reward.pth")
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'epoch': epoch,
                    'avg_reward': avg_reward,
                    'optimizer_state_dict': trainer.optimizer.state_dict(),
                    'rl_config': {'lr': rl_lr}
                }, best_save_path)
                print(f"ğŸŒŸ [New Best] Avg Reward {avg_reward:.4f} achieved! Model saved to {best_save_path}")

            # === [MODIFIED] ä¿å­˜é€»è¾‘ B: æ¯ 10 ä¸ª Epoch ä¿å­˜ä¸€æ¬¡ ===
            if (epoch + 1) % 10 == 0:
                rl_save_path = os.path.join(train_config['output_dir'], f"rl_finetuned_epoch_{epoch+1}.pth")
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'epoch': epoch,
                    'avg_reward': avg_reward,
                    'optimizer_state_dict': trainer.optimizer.state_dict(),
                    'rl_config': {'lr': rl_lr}
                }, rl_save_path)
                print(f"ğŸ’¾ [Checkpoint] Epoch {epoch+1} saved to {rl_save_path}")
                
    else:
        # åŸæœ‰çš„ç›‘ç£è®­ç»ƒé€»è¾‘
        print(">>> Starting Standard Supervised Training <<<")
        print(f"Total Epochs: {train_config['epochs']} | Batch Size: {batch_size}")
        
        trainer = trainers.LayoutTrainer(model, train_loader, val_loader, config, tokenizer, example_poem, test_loader)
        trainer.train()

if __name__ == "__main__":
    main()